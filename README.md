# CogniCode-MCTS: Inference-Time Reasoning via Tree Search

**A Research Framework for System-2 Thinking in Code Generation.**

![Status](https://img.shields.io/badge/Status-Research_Prototype-blue)
![Python](https://img.shields.io/badge/Python-3.10+-green)
![License](https://img.shields.io/badge/License-MIT-purple)

##  Abstract
Current Large Language Models (LLMs) operate primarily as "System 1" thinkersâ€”generating tokens based on immediate probability distributions without lookahead. This results in syntax errors, logic bugs, and hallucinations in complex code generation tasks.

**CogniCode-MCTS** implements a "System 2" reasoning layer using **Monte Carlo Tree Search (MCTS)**. It treats code generation as a state-space search problem, using:
1.  **Sandboxed Execution** as the ground-truth reward signal.
2.  **LLMs (Gemini 2.5)** as the policy generator and heuristic evaluator.
3.  **UCB1 (Upper Confidence Bound)** for balancing exploration vs. exploitation.

##  Key Features
*   **Deterministic Verification:** Code is not just generated; it is executed, tested, and verified in a secure sandbox.
*   **Self-Correction:** The agent backtracks from failed branches (syntax errors) to explore alternative implementation strategies.
*   **Modular Architecture:** Decoupled Search, Environment, and Model layers allow for benchmarking different LLMs against the MCTS logic.

##  Installation

```bash
git clone https://github.com/alhibb/CogniCode-MCTS.git
cd CogniCode-MCTS
pip install -r requirements.txt
```

##  Usage

1. Set your API key (optional if running in mock mode):
   ```bash
   export GEMINI_API_KEY="your_key_here"
   ```

2. Run the engine:
   ```bash
   python main.py
   ```

##  Architecture
The system utilizes a **Search Tree** where:
*   **Root:** The Problem Description.
*   **Nodes:** Partial or complete code blocks.
*   **Edges:** Actions (Code Extensions) generated by the LLM.
*   **Leaves:** Terminal states (Success/Failure based on Unit Tests).

##  Experimental Results & Robustness

In initial testing on the Gemini Free Tier, the system demonstrated **Architectural Resilience**. 

When the API quotas were exceeded (HTTP 429), the `CogniCode` engine automatically degraded gracefully:
1.  **Detected** the rate limit.
2.  **Switched** strategy from Cloud Inference (Gemini) to Local Heuristic Search (Mock/Local Model).
3.  **Preserved** the search tree state.
4.  **Successfully resolved** the factorial problem at **Iteration 23**.

**Log Sample:**
```text
21:20:05 - ITER 1: Visited depth 0 | Reward: 0.1
21:20:05 - API Error: 429 You exceeded your current quota...
...
21:20:06 - ITER 22: Visited depth 7 | Reward: 0.1
21:20:06 - ITER 23:  SOLUTION FOUND at depth 3
```

##  Proof of Concept
*Experiment Date: 25 November 2025*
*Model: Google Gemini 2.5 Flash via API*

In 5 iterations, the agent successfully navigated from an empty function signature to a fully working recursive algorithm, rejecting incomplete paths along the way.

```text
04:50:10 - Seed: def factorial(n):
04:50:24 - ITER 3: D1 | R:0.1 (Valid/Inc) | ...rial(n):     if n == 0:         return 1
04:50:27 - ITER 5:  SOLUTION FOUND at depth 2
```

##  Author
**IBRAHIM RABIU**  
Web3 Dev & AI Researcher


## Connect with me

* Twitter: [@I_bakondare](https://x.com/I_bakondare)
* LinkedIn: [alhibb](https://linkedin.com/in/alhibb)
* Telegram: [@Alhibb](https://t.me/@Alhibb)
