# CogniCode-MCTS: Inference-Time Reasoning via Tree Search

**A Research Framework for System-2 Thinking in Code Generation.**

![Status](https://img.shields.io/badge/Status-Research_Prototype-blue)
![Python](https://img.shields.io/badge/Python-3.10+-green)
![License](https://img.shields.io/badge/License-MIT-purple)

##  Abstract
Current Large Language Models (LLMs) operate primarily as "System 1" thinkersâ€”generating tokens based on immediate probability distributions without lookahead. This results in syntax errors, logic bugs, and hallucinations in complex code generation tasks.

**CogniCode-MCTS** implements a "System 2" reasoning layer using **Monte Carlo Tree Search (MCTS)**. It treats code generation as a state-space search problem, using:
1.  **Sandboxed Execution** as the ground-truth reward signal.
2.  **LLMs (Gemini 1.5)** as the policy generator and heuristic evaluator.
3.  **UCB1 (Upper Confidence Bound)** for balancing exploration vs. exploitation.

##  Key Features
*   **Deterministic Verification:** Code is not just generated; it is executed, tested, and verified in a secure sandbox.
*   **Self-Correction:** The agent backtracks from failed branches (syntax errors) to explore alternative implementation strategies.
*   **Modular Architecture:** Decoupled Search, Environment, and Model layers allow for benchmarking different LLMs against the MCTS logic.

##  Installation

```bash
git clone https://github.com/alhibb/CogniCode-MCTS.git
cd CogniCode-MCTS
pip install -r requirements.txt
```

##  Usage

1. Set your API key (optional if running in mock mode):
   ```bash
   export GEMINI_API_KEY="your_key_here"
   ```

2. Run the engine:
   ```bash
   python main.py
   ```

##  Architecture
The system utilizes a **Search Tree** where:
*   **Root:** The Problem Description.
*   **Nodes:** Partial or complete code blocks.
*   **Edges:** Actions (Code Extensions) generated by the LLM.
*   **Leaves:** Terminal states (Success/Failure based on Unit Tests).

##  Experimental Results & Robustness

In initial testing on the Gemini Free Tier, the system demonstrated **Architectural Resilience**. 

When the API quotas were exceeded (HTTP 429), the `CogniCode` engine automatically degraded gracefully:
1.  **Detected** the rate limit.
2.  **Switched** strategy from Cloud Inference (Gemini) to Local Heuristic Search (Mock/Local Model).
3.  **Preserved** the search tree state.
4.  **Successfully resolved** the factorial problem at **Iteration 23**.

**Log Sample:**
```text
21:20:05 - ITER 1: Visited depth 0 | Reward: 0.1
21:20:05 - API Error: 429 You exceeded your current quota...
...
21:20:06 - ITER 22: Visited depth 7 | Reward: 0.1
21:20:06 - ITER 23:  SOLUTION FOUND at depth 3
```

##  Author
**IBRAHIM RABIU**  
Web3 Dev & AI Researcher

