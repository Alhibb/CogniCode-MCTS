

#### `.gitignore`
```text
__pycache__/
*.pyc
.env
.DS_Store
venv/
.pytest_cache/
logs/
output/
```

#### `LICENSE`
```text
MIT License

Copyright (c) 2024 [Your Name]

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

#### `requirements.txt`
```text
numpy>=1.24.0
google-generativeai>=0.3.0
python-dotenv>=1.0.0
pytest>=7.4.0
colorama>=0.4.6
```

#### `README.md`
```markdown
# CogniCode-MCTS: Inference-Time Reasoning via Tree Search

**A Research Framework for System-2 Thinking in Code Generation.**

![Status](https://img.shields.io/badge/Status-Research_Prototype-blue)
![Python](https://img.shields.io/badge/Python-3.10+-green)
![License](https://img.shields.io/badge/License-MIT-purple)

## ðŸ”¬ Abstract
Current Large Language Models (LLMs) operate primarily as "System 1" thinkersâ€”generating tokens based on immediate probability distributions without lookahead. This results in syntax errors, logic bugs, and hallucinations in complex code generation tasks.

**CogniCode-MCTS** implements a "System 2" reasoning layer using **Monte Carlo Tree Search (MCTS)**. It treats code generation as a state-space search problem, using:
1.  **Sandboxed Execution** as the ground-truth reward signal.
2.  **LLMs (Gemini 1.5)** as the policy generator and heuristic evaluator.
3.  **UCB1 (Upper Confidence Bound)** for balancing exploration vs. exploitation.

## ðŸš€ Key Features
*   **Deterministic Verification:** Code is not just generated; it is executed, tested, and verified in a secure sandbox.
*   **Self-Correction:** The agent backtracks from failed branches (syntax errors) to explore alternative implementation strategies.
*   **Modular Architecture:** Decoupled Search, Environment, and Model layers allow for benchmarking different LLMs against the MCTS logic.

## ðŸ› ï¸ Installation

```bash
git clone https://github.com/alhibb/CogniCode-MCTS.git
cd CogniCode-MCTS
pip install -r requirements.txt
```

## ðŸƒ Usage

1. Set your API key (optional if running in mock mode):
   ```bash
   export GEMINI_API_KEY="your_key_here"
   ```

2. Run the engine:
   ```bash
   python main.py
   ```

## ðŸ§  Architecture
The system utilizes a **Search Tree** where:
*   **Root:** The Problem Description.
*   **Nodes:** Partial or complete code blocks.
*   **Edges:** Actions (Code Extensions) generated by the LLM.
*   **Leaves:** Terminal states (Success/Failure based on Unit Tests).

## ðŸ‘¨â€ðŸ’» Author
**[Your Name]**  
Senior Software Engineer & AI Researcher
```

---

### 2. Documentation Layer

#### `docs/RESEARCH_PROPOSAL.md`
```markdown
# Research Proposal: Enhancing Gemini Code Capabilities via Inference-Time Search

## 1. Executive Summary
We propose a framework to enhance the coding capabilities of Gemini models not by increasing parameter count, but by implementing **Inference-Time Compute** using Monte Carlo Tree Search (MCTS). This approach moves the burden of correctness from the training phase to the inference phase, allowing the model to "think," backtrack, and verify before responding.

## 2. Problem Statement
Autoregressive models (LLMs) generate code token-by-token.
*   **No Lookahead:** If the model makes a logic error in step 1, it tries to justify it in step 2 rather than correcting it.
*   **Stochasticity:** Even powerful models (Gemini Ultra) occasionally produce code that fails syntax checks or edge cases.
*   **Lack of Ground Truth:** The model optimizes for *probability*, not *compilability*.

## 3. Methodology: CogniCode-MCTS
We model code generation as a decision tree.

### 3.1 The Algorithm
1.  **Selection:** We use the UCB1 formula to traverse the tree to a leaf node that maximizes potential value while encouraging exploration of unvisited states.
    $$ UCB = \frac{w_i}{n_i} + C \sqrt{\frac{\ln N_i}{n_i}} $$
2.  **Expansion:** The LLM acts as the "Policy Network," proposing $k$ possible next lines of code or functional blocks.
3.  **Simulation (Evaluation):**
    *   **Level 1 (Fast):** Static Analysis via Python AST to reject syntax errors (Reward: -1.0).
    *   **Level 2 (Slow):** Execution via `subprocess` against a unit test harness (Reward: 1.0 if pass, 0.0 if fail).
    *   **Level 3 (Heuristic):** If the code is incomplete, the LLM acts as a "Value Network" to estimate the probability of success from the current state.
4.  **Backpropagation:** Results are propagated up the tree, updating the win/visit ratios of all parent nodes.

## 4. Expected Impact
*   **Higher Pass@1 Rate:** By filtering out invalid paths internally, the user receives a verified solution.
*   **Efficiency:** Allows smaller, cheaper models (Gemini Flash) to achieve results comparable to larger models (Gemini Ultra) by spending more time on search.

## 5. Conclusion
This project demonstrates that integrating classical control theory (Search) with generative AI (LLMs) is the path toward **System 2 Reasoning** in software engineering agents.
```

#### `docs/architecture_diagram.txt` (Mermaid Code)
*Note: You can render this on GitHub or any Mermaid viewer.*

```mermaid
graph TD
    User[User Prompt] --> Root[MCTS Root Node]
    Root --> Select{Selection (UCB1)}
    Select -->|Traverse Tree| Leaf[Leaf Node]
    Leaf --> Expand[Expansion (LLM Generation)]
    Expand --> Cand1[Candidate 1]
    Expand --> Cand2[Candidate 2]
    Expand --> Cand3[Candidate 3]
    
    subgraph Environment [Sandboxed Environment]
        Cand1 --> AST[AST Syntax Check]
        AST -->|Valid| Exec[Runtime Execution]
        Exec -->|Pass/Fail| Reward[Calculate Reward]
    end
    
    Reward --> Backprop[Backpropagation]
    Backprop -->|Update Values| Root
```

---

### 3. Source Code (`src/`)

#### `src/__init__.py`
*(Empty file)*

#### `src/utils/logger.py`
```python
import logging
import sys
from colorama import Fore, Style, init

init(autoreset=True)

def setup_logger(name: str = "CogniCode"):
    logger = logging.getLogger(name)
    logger.setLevel(logging.INFO)
    
    handler = logging.StreamHandler(sys.stdout)
    formatter = logging.Formatter(f'{Fore.CYAN}%(asctime)s{Style.RESET_ALL} - %(message)s', datefmt='%H:%M:%S')
    handler.setFormatter(formatter)
    
    if not logger.handlers:
        logger.addHandler(handler)
        
    return logger

logger = setup_logger()
```

#### `src/mcts/__init__.py`
*(Empty file)*

#### `src/mcts/node.py`
```python
import math
from typing import List, Optional

class MCTSNode:
    """
    Represents a state in the code generation tree.
    """
    def __init__(self, state: str, parent: Optional['MCTSNode'] = None):
        self.state = state  # The code string generated so far
        self.parent = parent
        self.children: List['MCTSNode'] = []
        self.visits: int = 0
        self.value: float = 0.0 
        self.is_terminal: bool = False
        self.is_fully_expanded: bool = False

    def ucb1(self, exploration_weight: float = 1.41) -> float:
        """
        Calculates Upper Confidence Bound.
        """
        if self.visits == 0:
            return float('inf')
        
        # Avoid division by zero for parent visits in root case
        parent_visits = self.parent.visits if self.parent else 1
        if parent_visits == 0:
            parent_visits = 1

        exploitation = self.value / self.visits
        exploration = exploration_weight * math.sqrt(math.log(parent_visits) / self.visits)
        return exploitation + exploration

    def best_child(self) -> Optional['MCTSNode']:
        if not self.children:
            return None
        return max(self.children, key=lambda c: c.ucb1())

    def __repr__(self):
        return f"<Node visits={self.visits} val={self.value:.2f} len={len(self.state)}>"
```

#### `src/mcts/engine.py`
```python
import random
from typing import Optional
from src.mcts.node import MCTSNode
from src.environment.sandbox import CodeSandbox
from src.llm.abstract_client import AbstractLLMClient
from src.utils.logger import logger

class MCTSEngine:
    """
    The orchestrator implementing the Monte Carlo Tree Search algorithm.
    """
    def __init__(self, llm_client: AbstractLLMClient, problem_desc: str, test_harness: str):
        self.llm = llm_client
        self.problem = problem_desc
        self.test_harness = test_harness
        self.sandbox = CodeSandbox()
        # The root state usually contains imports or the function header
        self.root = MCTSNode(state="") 

    def run(self, iterations: int = 10) -> str:
        logger.info(f"Starting MCTS Search for {iterations} iterations...")
        
        for i in range(iterations):
            # 1. Selection
            node = self._select(self.root)
            
            # 2. Expansion
            # If the node isn't a terminal state (success), expand it
            if not node.is_terminal:
                if node.visits > 0:
                    node = self._expand(node)
                # If visits == 0, we simulate the node itself (Rollout)
            
            # 3. Simulation
            reward = self._simulate(node)
            
            # 4. Backpropagation
            self._backpropagate(node, reward)
            
            # Logging for visualization
            if reward == 1.0:
                logger.info(f"ITER {i+1}: ðŸŒŸ SOLUTION FOUND at depth {self._get_depth(node)}")
                return node.state
            else:
                logger.info(f"ITER {i+1}: Visited depth {self._get_depth(node)} | Reward: {reward}")

        # Fallback: Return best visited path
        best_node = self._get_best_child(self.root)
        logger.warning("Max iterations reached. Returning best partial solution.")
        return best_node.state

    def _select(self, node: MCTSNode) -> MCTSNode:
        """Traverse down the tree using UCB1 until a leaf or unexpanded node is found."""
        while node.children and node.is_fully_expanded:
            node = node.best_child()
        return node

    def _expand(self, node: MCTSNode) -> MCTSNode:
        """Ask LLM for N variations of the next step."""
        candidates = self.llm.generate_candidates(self.problem, node.state, n=3)
        
        for code_snippet in candidates:
            # Combine previous state with new snippet
            new_state = f"{node.state}\n{code_snippet}".strip()
            child = MCTSNode(state=new_state, parent=node)
            node.children.append(child)
        
        node.is_fully_expanded = True
        
        # Return a random child to start simulation
        return random.choice(node.children)

    def _simulate(self, node: MCTSNode) -> float:
        """Run the code in the sandbox."""
        result = self.sandbox.execute(node.state, self.test_harness)
        
        if result['success']:
            node.is_terminal = True
            return 1.0
        elif result['error_type'] == 'syntax':
            return -1.0 # Heavy penalty for invalid syntax
        else:
            # Code runs but fails logic. 
            # In a full version, we would use LLM heuristic here.
            # For now, small reward for runnable code.
            return 0.1

    def _backpropagate(self, node: Optional[MCTSNode], reward: float):
        while node:
            node.visits += 1
            node.value += reward
            node = node.parent

    def _get_best_child(self, node: MCTSNode) -> MCTSNode:
        if not node.children: return node
        return max(node.children, key=lambda c: c.visits)

    def _get_depth(self, node: MCTSNode) -> int:
        depth = 0
        curr = node
        while curr.parent:
            depth += 1
            curr = curr.parent
        return depth
```

#### `src/environment/__init__.py`
*(Empty file)*

#### `src/environment/sandbox.py`
```python
import subprocess
import tempfile
import os
import sys
import ast
from typing import Dict, Any

class CodeSandbox:
    """
    Isolated execution environment. 
    Uses subprocess to prevent the agent from crashing the main thread.
    """
    
    @staticmethod
    def validate_syntax(code: str) -> bool:
        """Fast check to avoid spinning up processes for garbage code."""
        try:
            ast.parse(code)
            return True
        except SyntaxError:
            return False

    def execute(self, code: str, test_harness: str) -> Dict[str, Any]:
        """
        Executes code + tests.
        Returns: {success: bool, score: float, error_type: str, output: str}
        """
        # 1. AST Static Analysis
        if not self.validate_syntax(code):
            return {
                "success": False, 
                "score": -1.0, 
                "error_type": "syntax", 
                "output": "Syntax Error"
            }

        # 2. Prepare Payload
        full_script = f"{code}\n\n{test_harness}"
        
        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
            f.write(full_script)
            script_path = f.name

        # 3. Execution with Timeout
        try:
            # We run the script in a separate python process
            result = subprocess.run(
                [sys.executable, script_path],
                capture_output=True,
                text=True,
                timeout=2.0 # Strict 2s timeout for infinite loops
            )
            
            output = result.stdout + result.stderr
            
            if result.returncode == 0:
                return {
                    "success": True, 
                    "score": 1.0, 
                    "error_type": None, 
                    "output": output
                }
            else:
                return {
                    "success": False, 
                    "score": 0.0, 
                    "error_type": "runtime", 
                    "output": output
                }

        except subprocess.TimeoutExpired:
            return {
                "success": False, 
                "score": -0.5, 
                "error_type": "timeout", 
                "output": "Execution Timeout"
            }
        finally:
            # Cleanup
            if os.path.exists(script_path):
                os.remove(script_path)
```

#### `src/llm/__init__.py`
*(Empty file)*

#### `src/llm/abstract_client.py`
```python
from abc import ABC, abstractmethod
from typing import List

class AbstractLLMClient(ABC):
    @abstractmethod
    def generate_candidates(self, problem: str, current_state: str, n: int = 3) -> List[str]:
        """
        Generates 'n' possible continuations for the code.
        """
        pass
```

#### `src/llm/gemini_client.py`
```python
import os
import random
from typing import List
import google.generativeai as genai
from src.llm.abstract_client import AbstractLLMClient
from src.utils.logger import logger

class GeminiClient(AbstractLLMClient):
    def __init__(self, api_key: str = None, mock_mode: bool = False):
        self.mock_mode = mock_mode
        if not mock_mode:
            self.api_key = api_key or os.getenv("GEMINI_API_KEY")
            if not self.api_key:
                logger.warning("No API Key found. Switching to MOCK MODE.")
                self.mock_mode = True
            else:
                genai.configure(api_key=self.api_key)
                self.model = genai.GenerativeModel('gemini-1.5-flash')

    def generate_candidates(self, problem: str, current_state: str, n: int = 3) -> List[str]:
        if self.mock_mode:
            return self._mock_generator(current_state, n)
        
        # Real API Implementation
        prompt = f"""
        You are a Python coding assistant.
        Problem: {problem}
        
        Current Code Context:
        {current_state}
        
        Instructions:
        1. Generate exactly {n} distinct continuations for the next logical step.
        2. Do not repeat code already in context.
        3. Output only the code, separated by '|||' delimiter.
        """
        
        try:
            response = self.model.generate_content(prompt)
            # Naive parsing strategy - in prod this would be more robust
            candidates = response.text.split('|||')
            return [c.strip().replace('```python', '').replace('```', '') for c in candidates[:n]]
        except Exception as e:
            logger.error(f"API Error: {e}")
            return self._mock_generator(current_state, n)

    def _mock_generator(self, current_state: str, n: int) -> List[str]:
        """
        Simulates an LLM for testing without costs.
        Scenario: Writing a recursive factorial function.
        """
        candidates = []
        
        # State 0: Start
        if "def" not in current_state:
            return [
                "def factorial(n):",
                "def solve(n):", 
                "def fact(x):"
            ]
        
        # State 1: Inside Function
        if "factorial(n):" in current_state and "if" not in current_state:
            return [
                "    if n == 0: return 1",  # Correct path
                "    if n == 1: return 1",  # Okay path
                "    if n < 0: return None" # Defensive path
            ]
            
        # State 2: Recursive step
        if "return 1" in current_state and "return n" not in current_state:
            return [
                "    return n * factorial(n-1)", # Correct
                "    return n * factorial(n)",   # Infinite recursion (Bug)
                "    return n + factorial(n-1)"  # Logic bug
            ]
            
        return ["    pass"]
```

---

### 4. Integration Tests

#### `tests/test_integration.py`
```python
import pytest
from src.mcts.engine import MCTSEngine
from src.llm.gemini_client import GeminiClient

def test_full_flow_mocked():
    """
    Tests the entire pipeline using the Mock LLM.
    Ensures that the tree search eventually finds the correct factorial implementation.
    """
    # 1. Setup Mock Client
    client = GeminiClient(mock_mode=True)
    
    # 2. Problem & Harness
    problem = "Write a factorial function."
    test_harness = """
if __name__ == "__main__":
    assert factorial(5) == 120
    assert factorial(0) == 1
"""

    # 3. Init Engine
    engine = MCTSEngine(client, problem, test_harness)
    
    # 4. Run Search
    result_code = engine.run(iterations=20)
    
    # 5. Assertions
    assert "def factorial(n):" in result_code
    assert "return n * factorial(n-1)" in result_code
    print("\nTest Passed: Agent successfully navigated the search tree.")

if __name__ == "__main__":
    test_full_flow_mocked()
```

---

### 5. Main Entry Point

#### `main.py`
```python
import os
from src.mcts.engine import MCTSEngine
from src.llm.gemini_client import GeminiClient
from src.utils.logger import logger

def main():
    logger.info("Initializing CogniCode-MCTS Environment...")

    # 1. Configuration
    # Tries to load real key, falls back to Mock if not found
    api_key = os.getenv("GEMINI_API_KEY")
    client = GeminiClient(api_key=api_key)
    
    # 2. Define the Challenge
    # We want the agent to write a recursive factorial function.
    problem_description = "Write a recursive Python function named 'factorial' that calculates the factorial of a non-negative integer."
    
    # 3. Define the 'Ground Truth' (The invisible unit test)
    # The agent does not see this; the sandbox uses it to validate execution.
    test_harness = """
if __name__ == "__main__":
    try:
        assert factorial(5) == 120
        assert factorial(0) == 1
        assert factorial(3) == 6
    except NameError:
        exit(1) # Fail if function not defined
    except AssertionError:
        exit(1) # Fail if logic is wrong
"""

    # 4. Initialize Engine
    engine = MCTSEngine(client, problem_description, test_harness)
    
    # 5. Run Search
    logger.info(f"Problem: {problem_description}")
    final_code = engine.run(iterations=30)
    
    print("\n" + "="*40)
    print("ðŸ† FINAL GENERATED CODE")
    print("="*40)
    print(final_code)
    print("="*40)

if __name__ == "__main__":
    main()
```